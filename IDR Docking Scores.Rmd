---
title: "IDR Docking Scores for NSP15 Endoribonuclease"
author: "Andrew Chen"
date: "7/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(idr)
```

>Lack of consistency in virtual screening and structure reproduction results is the Achilles' heel of docking programs. They tend to do very well on some systems and terribly on others. The worst virtual screening method (measured by AUC) is on average only slightly better than random; nevertheless, it is expected to outperform the best virtual screening method (measured by AUC) 1 in 7 times. (FRED Pose Prediction and Virtual Screening Accuracy)


- FRED: Score is an estimate of Binding Affinity. 
- Autodock Vina. Score is an estimate of Binding Affinity.
- DOCK6. Dock Score is an estimate of approximate binding energy (more positive indicates better binding.)

### Importing Data
```{r}
dock6 <- read.delim("~/Downloads/DockingScores/NSP15_6W01_AB_1_F.dock6.results.txt")
fred <- read.delim("~/Downloads/DockingScores/NSP15_6W01_AB_1_F.fred.results.txt")
vina <- read.delim("~/Downloads/DockingScores/NSP15_6W01_AB_1_F.vina.results.txt")
```

### Comparing Ranks
```{r}
#rank, gives ranks starting from lowest, order is like np.argsort
dock6["dock_rank"] <- rank(dock6$Score)
fred["fred_rank"] <- rank(-1*fred$Score)
vina["vina_rank"] <- rank(-1*vina$Score)

merged_ranks <- merge(merge(dock6, fred, by = "Title"), vina, by = "Title")
merged_ranks <- select(merged_ranks, dock_rank, fred_rank, vina_rank)
```

```{r}
pairs(merged_ranks, pch = 20)
```
```{r}
print(c(cor(merged_ranks$dock_rank, merged_ranks$fred_rank, method = "spearman"),
      cor(merged_ranks$fred_rank, merged_ranks$vina_rank, method = "spearman"),
      cor(merged_ranks$dock_rank, merged_ranks$vina_rank, method = "spearman")))
```

### IDR

```{r}
# Correspondence Curves
dock_fred <- get.correspondence(merged_ranks$dock_rank, merged_ranks$fred_rank, seq(0.01,0.99,by = 1/2928))
dock_vina <- get.correspondence(merged_ranks$dock_rank, merged_ranks$vina_rank, seq(0.01,0.99,by = 1/2928))
vina_fred <- get.correspondence(merged_ranks$vina_rank, merged_ranks$fred_rank, seq(0.01,0.99,by = 1/2928))
```

```{r}
plot(dock_fred$psi$t, dock_fred$psi$value, xlab="t", ylab="psi", main = "Dock_Fred correspondence", xlim=c(0, max(dock_fred$psi$t)), ylim=c(0, max(dock_fred$psi$value)), cex.lab=2)
lines(dock_fred$psi$smoothed.line, lwd=4)
abline(coef=c(0,1), lty=3)
```
```{r}
plot(dock_vina$psi$t, dock_vina$psi$value, xlab="t", ylab="psi", main = "Dock_Vina Correspondence", xlim=c(0, max(dock_vina$psi$t)), ylim=c(0, max(dock_vina$psi$value)), cex.lab=2)
lines(dock_vina$psi$smoothed.line, lwd=4)
abline(coef=c(0,1), lty=3)
```
```{r}
plot(vina_fred$psi$t, vina_fred$psi$value, xlab="t", ylab="psi", main = "Vina_Fred Correspondence", xlim=c(0, max(vina_fred$psi$t)), ylim=c(0, max(vina_fred$psi$value)), cex.lab=2)
lines(vina_fred$psi$smoothed.line, lwd=4)
abline(coef=c(0,1), lty=3)
```

```{r}
mu <- 2.6
sigma <- 2.5
rho <- 0.3
p <- 0.1
idr.out <- est.IDR(merged_ranks, mu, sigma, rho, p, eps=0.001, max.ite=20)
# select observations exceeding IDR threshold=0.01
IDR.level <- 0.01
obs.selected <- select.IDR(merged_ranks, idr.out$IDR, IDR.level)
```

```{r}
obs.selected$n
```

```{r}
top_200 <- order(idr.out$idr)[1:200]
plot(seq(200), idr.out$idr[top_200], xlab = "observation", ylab = "local IDR")
```


### Contour plot of selected observations given starting values
```{r}
contour_data  <- matrix(nrow = 861,ncol = 3)

mu <- 2.6
p <- 0.1
IDR.level <- 0.01
counter <- 1

for (i in seq(1,3,by=1/20)) {
  for (j in seq(0,1,by=1/20)) {
    sigma <- i
    rho <- j
    idr.out <- est.IDR(merged_ranks, mu, sigma, rho, p, eps=0.001, max.ite=20)
    obs.selected <- select.IDR(merged_ranks, idr.out$IDR, IDR.level)
    row <- c(sigma, rho, obs.selected$n)
    #print(row)
    contour_data[counter,] <- row
    #print(counter)
    counter <- counter + 1
  }
}
```

