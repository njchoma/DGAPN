Arguments initialized.
1.321 baseline L2 loss

MyGNN(
  (layers): ModuleList(
    (0): MyGAT(121, 256, heads=2)
    (1): MyGAT(256, 256, heads=2)
    (2): MyGAT(256, 256, heads=2)
    (3): MyGAT(256, 256, heads=2)
  )
  (final_layer): Linear(in_features=256, out_features=1, bias=True)
)
New model created


Epoch 1
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 3.70
      700160: 3.08
     1050240: 2.64
     1400320: 2.35
     1750400: 2.12
     2100480: 1.94
     2450560: 1.80
     2800640: 1.69
     3150720: 1.59
     3500800: 1.52
  Model elapsed:  1600.64
  Loader elapsed: 60.74
  Total elapsed:  1661.38

  Valid:
  9117 batches, 1166976 samples
      291712: 0.82
      583424: 0.82
      875136: 0.82
     1166848: 0.83
  Model elapsed:  111.70
  Loader elapsed: 378.26
  Total elapsed:  489.96
Train MSE: 1.52
Valid MSE: 0.83
Best performance on valid set
2151.4 seconds, this epoch


Epoch 2
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 0.80
      700160: 0.80
     1050240: 0.79
     1400320: 0.79
     1750400: 0.78
     2100480: 0.78
     2450560: 0.77
     2800640: 0.77
     3150720: 0.77
     3500800: 0.76
  Model elapsed:  1541.42
  Loader elapsed: 63.25
  Total elapsed:  1604.67

  Valid:
  9117 batches, 1166976 samples
      291712: 0.73
      583424: 0.73
      875136: 0.73
     1166848: 0.73
  Model elapsed:  114.17
  Loader elapsed: 376.84
  Total elapsed:  491.01
Train MSE: 0.76
Valid MSE: 0.73
Best performance on valid set
2095.7 seconds, this epoch


Epoch 3
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 0.73
      700160: 0.73
     1050240: 0.73
     1400320: 0.73
     1750400: 0.72
     2100480: 0.72
     2450560: 0.72
     2800640: 0.72
     3150720: 0.72
     3500800: 0.72
  Model elapsed:  1538.47
  Loader elapsed: 63.85
  Total elapsed:  1602.32

  Valid:
  9117 batches, 1166976 samples
      291712: 0.70
      583424: 0.71
      875136: 0.71
     1166848: 0.71
  Model elapsed:  116.78
  Loader elapsed: 369.48
  Total elapsed:  486.26
Train MSE: 0.72
Valid MSE: 0.71
Best performance on valid set
2088.6 seconds, this epoch


Epoch 4
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 0.70
      700160: 0.70
     1050240: 0.70
     1400320: 0.70
     1750400: 0.70
     2100480: 0.70
     2450560: 0.70
     2800640: 0.70
     3150720: 0.70
     3500800: 0.70
  Model elapsed:  1551.72
  Loader elapsed: 63.72
  Total elapsed:  1615.45

  Valid:
  9117 batches, 1166976 samples
      291712: 0.68
      583424: 0.69
      875136: 0.69
     1166848: 0.69
  Model elapsed:  113.86
  Loader elapsed: 383.38
  Total elapsed:  497.24
Train MSE: 0.70
Valid MSE: 0.69
Best performance on valid set
2112.7 seconds, this epoch


Epoch 5
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 0.68
      700160: 0.68
     1050240: 0.68
     1400320: 0.68
     1750400: 0.68
     2100480: 0.68
     2450560: 0.68
     2800640: 0.68
     3150720: 0.68
     3500800: 0.68
  Model elapsed:  1537.91
  Loader elapsed: 62.99
  Total elapsed:  1600.90

  Valid:
  9117 batches, 1166976 samples
      291712: 0.67
      583424: 0.68
      875136: 0.68
     1166848: 0.68
  Model elapsed:  112.45
  Loader elapsed: 369.62
  Total elapsed:  482.07
Train MSE: 0.68
Valid MSE: 0.68
Best performance on valid set
2083.0 seconds, this epoch


Epoch 6
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 0.67
      700160: 0.67
     1050240: 0.67
     1400320: 0.67
     1750400: 0.67
     2100480: 0.67
     2450560: 0.67
     2800640: 0.67
     3150720: 0.67
     3500800: 0.67
  Model elapsed:  1540.03
  Loader elapsed: 65.92
  Total elapsed:  1605.94

  Valid:
  9117 batches, 1166976 samples
      291712: 0.66
      583424: 0.67
      875136: 0.67
     1166848: 0.67
  Model elapsed:  111.82
  Loader elapsed: 381.09
  Total elapsed:  492.92
Train MSE: 0.67
Valid MSE: 0.67
Best performance on valid set
2098.9 seconds, this epoch


Epoch 7
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 0.67
      700160: 0.67
     1050240: 0.66
     1400320: 0.66
     1750400: 0.66
     2100480: 0.66
     2450560: 0.66
     2800640: 0.66
     3150720: 0.66
     3500800: 0.66
  Model elapsed:  1549.50
  Loader elapsed: 61.60
  Total elapsed:  1611.10

  Valid:
  9117 batches, 1166976 samples
      291712: 0.66
      583424: 0.66
      875136: 0.66
     1166848: 0.66
  Model elapsed:  113.43
  Loader elapsed: 376.57
  Total elapsed:  489.99
Train MSE: 0.66
Valid MSE: 0.66
Best performance on valid set
2101.1 seconds, this epoch


Epoch 8
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 0.66
      700160: 0.66
     1050240: 0.66
     1400320: 0.66
     1750400: 0.66
     2100480: 0.66
     2450560: 0.66
     2800640: 0.66
     3150720: 0.66
     3500800: 0.66
  Model elapsed:  1546.68
  Loader elapsed: 64.01
  Total elapsed:  1610.68

  Valid:
  9117 batches, 1166976 samples
      291712: 0.65
      583424: 0.66
      875136: 0.66
     1166848: 0.66
  Model elapsed:  115.29
  Loader elapsed: 370.58
  Total elapsed:  485.87
Train MSE: 0.66
Valid MSE: 0.66
Best performance on valid set
2096.6 seconds, this epoch


Epoch 9
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 0.65
      700160: 0.65
     1050240: 0.65
     1400320: 0.65
     1750400: 0.65
     2100480: 0.65
     2450560: 0.65
     2800640: 0.65
     3150720: 0.65
     3500800: 0.65
  Model elapsed:  1575.51
  Loader elapsed: 60.36
  Total elapsed:  1635.87

  Valid:
  9117 batches, 1166976 samples
      291712: 0.65
      583424: 0.65
      875136: 0.65
     1166848: 0.65
  Model elapsed:  119.87
  Loader elapsed: 379.84
  Total elapsed:  499.71
Train MSE: 0.65
Valid MSE: 0.65
Best performance on valid set
2135.6 seconds, this epoch


Epoch 10
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 0.65
      700160: 0.65
     1050240: 0.65
     1400320: 0.65
     1750400: 0.65
     2100480: 0.65
     2450560: 0.65
     2800640: 0.65
     3150720: 0.65
     3500800: 0.65
  Model elapsed:  1550.88
  Loader elapsed: 59.68
  Total elapsed:  1610.56

  Valid:
  9117 batches, 1166976 samples
      291712: 0.65
      583424: 0.65
      875136: 0.65
     1166848: 0.65
  Model elapsed:  116.66
  Loader elapsed: 389.71
  Total elapsed:  506.37
Train MSE: 0.65
Valid MSE: 0.65
2116.9 seconds, this epoch


Epoch 11
Learning rate: 0.001
  Train:
  27350 batches, 3500800 samples
      350080: 0.65
      700160: 0.64
     1050240: 0.64
     1400320: 0.64
     1750400: 0.64
     2100480: 0.64
     2450560: 0.64
